╔==============================================================================╗
║                    CONSOLIDATED TOKEN USAGE REPORT                           ║
║                                                                              ║
║               BGE-M3 Embeddings + Groq LLM (Llama 3.3 70B)                   ║
╚==============================================================================╝

┌──────────────────────────────────────────────────────────────────────────────┐
│ SCENARIO                                                                   │
├──────────────────────────────────────────────────────────────────────────────┤
│ • Documents to ingest:  45                                                    │
│ • Average tokens per document:  897                                           │
│ • Number of user queries: 200                                                  │
│ • Documents retrieved per query (top_k): 3                                      │
└──────────────────────────────────────────────────────────────────────────────┘

╔==============================================================================╗
║ PART 1: BGE-M3 EMBEDDING MODEL (Creating vector embeddings)               ║
╚==============================================================================╝

┌─────────────────────────────────────────────────────────────────────────────┐
│ Task 1: Document Ingestion (Convert 45 docs to embeddings)                 │
├─────────────────────────────────────────────────────────────────────────────┤
│   Documents:  45                                                               │
│   Tokens per document:  897                                                    │
│   TOTAL TOKENS:     40,365                                                │
└─────────────────────────────────────────────────────────────────────────────┘

┌─────────────────────────────────────────────────────────────────────────────┐
│ Task 2: Query Processing (Convert 200 questions to embeddings)             │
├─────────────────────────────────────────────────────────────────────────────┤
│   Queries: 200                                                               │
│   Tokens per query: ~15                                                   │
│   TOTAL TOKENS:      3,000                                                 │
└─────────────────────────────────────────────────────────────────────────────┘

╔═════════════════════════════════════════════════════════════════════════════╗
║ BGE-M3 SUBTOTAL:     43,365 tokens                                            ║
╚═════════════════════════════════════════════════════════════════════════════╝


╔==============================================================================╗
║ PART 2: GROQ LLM (Llama 3.3 70B) - Generating answers                     ║
╚==============================================================================╝

┌─────────────────────────────────────────────────────────────────────────────┐
│ Breakdown per RAG Query:                                                   │
├─────────────────────────────────────────────────────────────────────────────┤
│   System prompt:    37 tokens                                             │
│   User query:    15 tokens                                                │
│   Context (3 documents):   2691 tokens                                     │
│   LLM response:   150 tokens                                              │
│                                                                             │
│   INPUT tokens per query:   2743 tokens                                 │
│   OUTPUT tokens per query:   150 tokens                                 │
│   ───────────────────────────────────────────────                           │
│   TOTAL per query:   2893 tokens                                       │
└─────────────────────────────────────────────────────────────────────────────┘

┌─────────────────────────────────────────────────────────────────────────────┐
│ Total for 200 queries:                                                      │
├─────────────────────────────────────────────────────────────────────────────┤
│   INPUT tokens:    548,600                                            │
│   OUTPUT tokens:     30,000                                            │
└─────────────────────────────────────────────────────────────────────────────┘

╔═════════════════════════════════════════════════════════════════════════════╗
║ GROQ LLM SUBTOTAL:    578,600 tokens                                      ║
╚═════════════════════════════════════════════════════════════════════════════╝


╔==============================================================================╗
║ COST ESTIMATE (Groq LLM only)                                              ║
╚==============================================================================╝
┌─────────────────────────────────────────────────────────────────────────────┐
│   Input tokens: $ 0.3237  (   548,600 tokens @ $0.59/1M)       │
│   Output tokens: $ 0.0237  (    30,000 tokens @ $0.79/1M)       │
│   ──────────────────────────────                                            │
│   TOTAL COST: $ 0.3474                                                       │
└─────────────────────────────────────────────────────────────────────────────┘

NOTE: BGE-M3 embeddings are FREE (running locally), no API costs!


╔══════════════════════════════════════════════════════════════════════════════╗
║                                                                              ║
║                          GRAND TOTAL SUMMARY                                 ║
║                                                                              ║
╠══════════════════════════════════════════════════════════════════════════════╣
║  BGE-M3 Embeddings (ingestion + queries):      43,365 tokens            ║
║  Groq LLM (200 RAG queries):                  578,600 tokens            ║
║  ──────────────────────────────────────────────────────────────────────────  ║
║  TOTAL TOKENS:                                621,965 tokens            ║
║                                                                              ║
╚══════════════════════════════════════════════════════════════════════════════╝

┌──────────────────────────────────────────────────────────────────────────────┐
│ IMPORTANT NOTES:                                                           │
├──────────────────────────────────────────────────────────────────────────────┤
│                                                                            │
│ 1. BGE-M3 embeddings run LOCALLY (no API costs)                           │
│    • Only pay for Groq LLM API calls                                      │
│    • Estimated cost for 200 queries: ~$0.35                               │
│                                                                            │
│ 2. Token breakdown:                                                        │
│    • BGE-M3 tokens: For creating vector embeddings                        │
│    • Groq LLM tokens: For generating natural language responses           │
│                                                                            │
│ 3. Actual usage may vary based on:                                        │
│    • Real document content and length                                     │
│    • User query complexity                                                │
│    • Number of documents retrieved (top_k parameter)                      │
│    • LLM response length                                                  │
│                                                                            │
│ 4. Groq is significantly faster and cheaper than alternatives:            │
│    • Ultra-fast inference speed                                           │
│    • Competitive pricing                                                  │
│    • Excellent for production RAG systems                                 │
│                                                                            │
└──────────────────────────────────────────────────────────────────────────────┘